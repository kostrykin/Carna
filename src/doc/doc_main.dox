namespace LibCarna
{

/** \mainpage
  *
  * %LibCarna provides classes for simple real-time 3D visualization of biomedical data and beyond. It is named after
  * the greek god of organs (yup, they really did have even one for organs). It is based on OpenGL 3.3 and Eigen 3.
  *
  * Jump to:
  *     \ref QuickStart | \ref VersionLog | \ref testing "Test Suite Documentation"
  *
  * --
  *
  *  1. \ref QuickStart_FrameRenderer "The Frame Renderer":
  *     \ref RenderStages and \ref GeometryTypes
  *  2. \ref SceneGraph "The Scene Graph":
  *     \ref SceneGraph_SpecialSpatialClasses and \ref QuickStart_VolumeGridHelper
  *  3. \ref GeometryFeatures "Geometry Features":
  *     \ref GeometryFeatureLifecycle and \ref QuickStart_Materials
  *
  * \image html FrameRendererIntegrationTest/typical.png "rendering result from example code below"
  *
  * \section QuickStart Quick Start
  *
  *  -# Implement the abstract \ref base::GLContext class. If you're using Qt, you
  *     can simply instantiate the \ref base::QGLContextAdapter template.
  *  -# Instantiate and configure a \ref base::FrameRenderer, e.g. like this:
  *     \snippet IntegrationTests/FrameRendererIntegrationTest.cpp typical_renderer_setup
  *     The values of the `GEOMETRY_TYPE_` variables can be chosen arbitrary, but
  *     must be distinct.
  *  -# Assuming you have somehow loaded `data` and know the voxel `spacings`, build
  *     the \ref SceneGraph "scene graph", e.g. like this:
  *     \snippet IntegrationTests/FrameRendererIntegrationTest.cpp typical_scene_setup
  *  -# Issue the \ref base::FrameRenderer::render method:
  *     \snippet IntegrationTests/FrameRendererIntegrationTest.cpp typical_renderer_invocation
  *     This code produces the rendering above.
  *
  * --
  *
  * Now lets take a closer look at what the code presented above actually does.
  *
  * \subsection QuickStart_FrameRenderer The Frame Renderer
  *
  * The `%FrameRenderer` consists of multiple components, each of which defines a
  * particular aspect of the rendering logic. Those components are called *rendering
  * stages* because their rendering logic is executed sequentially. The rendering
  * results depends heavily on the stages order. There is no generally "correct"
  * order, because this always depends on what one actually expects. The
  * `%FrameRendererHelper` class assumes a
  * \ref helpers::DefaultRenderStageOrder "default order" that will lead to the
  * desired results in presumably almost all cases. Of course one could also leave
  * out this helper and add the stages to the renderer in any desired order manually.
  *
  * \see
  * The rendering process is explained \ref RenderingProcess "here" in detail.
  *
  * \subsubsection RenderStages Built-in Rendering Stages
  *
  * In the example code above, several typical rendering stages are used:
  *
  *   - The \ref presets::CuttingPlanesStage renders an arbitrary number of cutting
  *     planes through volume data.
  *   - The \ref presets::OpaqueRenderingStage renders opaque meshes, i.e. polygonal
  *     geometry.
  *   - The \ref presets::DRRStage produces a *digital radiograph reconstruct* of the
  *     volume data.
  *   - The \ref presets::OccludedRenderingStage ensures that meshes, that are
  *     actually occluded by other geometry that is closer to the viewer, shine
  *     through.
  *
  * At the moment the following other stages are available out-of-the-box:
  *
  *   - The \ref presets::MeshColorCodingStage implements a simple interface for
  *     mapping \ref FrameCoordinates "frame coordinates" to \ref base::Mesh objects.
  *   - The \ref presets::MIPStage implements *maximum intensity projections* of
  *     volume data.
  *   - The \ref presets::DVRStage renders volume data through application of an HUV
  *     to color transfer function.
  *   - The \ref presets::ParallaxStage produces stereoscopic renderings.
  *   - The \ref presets::TransparentRenderingStage renders transparent meshes.
  *
  * \subsubsection GeometryTypes Geometry Types
  *
  * As one may guess from this list, each scene might contain multiple types of
  * renderable objects. At least one could distinguish between polygonal and
  * volumetric objects. Planes are certainly a third type: They are neither polygonal
  * because they are infinitely extended, nor they are volumetric. This is the very
  * breakdown that was used in the example, but it is up to the user to choose a more
  * detailed classification if required. Note that each rendering stage expects to be
  * told which *geometry type* it should render. By using two `%CuttingPlanesStage`
  * instances with different geometry types for example, one could render multiple
  * cutting planes with different windowing settings.
  *
  * \subsection SceneGraph The Scene Graph
  *
  * %Carna represents spatial entities with instances of the `%Spatial` class. Such
  * entities can be renderable objects, as well as imaginary points in space. The
  * location of each spaital entity is determined relatively to another one that is
  * called its *parent*. This parent-child relationship induces a tree structure,
  * that is commonly referred to as \em scene \em graph. Such a scene graph
  * represents a scene. This has two implications: First, that each scene contains
  * exactly one node that has no parent, namely the tree's root. Second, that it is
  * sufficient to specify an arbitrary node in order to reach any other `%Spatial`
  * of the scene.
  *
  * \subsubsection SceneGraph_SpecialSpatialClasses Spatial Class Specializations
  *
  * The specific type of a `%Spatial` decides upon whether it is an inner node or a
  * leaf of the scene graph. If it is *allowed* to have children, the spatial entity
  * will be realized by an instance of the \ref base::Node class, even if it has no
  * children in a particular situation. In contrast, visible scene elements, i.e.
  * such that can be rendered, must always be leafs. They will be realized by
  * instances of the \ref base::Geometry class usually. Another leaf type is the
  * `%Camera` that not only has a location within the scene, but also specifies how
  * the 3D space is to be projected into 2D.
  *
  * It should be clear from the above why the root of a scene graph always is a
  * \ref base::Node instance. The coordinate system of the root is often called
  * *world space*. You can read more on the different coordinate systems and how they
  * are related to each other \ref CoordinateSystems "here".
  *
  * \see
  * Following classes simplify the `%Camera` handling:
  *     \ref presets::PerspectiveControl,
  *     \ref presets::CameraShowcaseControl,
  *     \ref presets::CameraNavigationControl
  *
  * \see
  * The \ref base::SpatialMovement class makes the implementation of drag-&-drop like
  * behaviour for `%Geometry` objects very easy.
  *
  * \subsubsection QuickStart_VolumeGridHelper Positioning CT Data
  *
  * The `VolumeGridHelper` class takes care of two things. First, it partitions the
  * volumetric `data` into multiple smaller, box-shaped volumes. This partitioning is
  * done according to an upper limit of each volume's memory size. It reduces the
  * probability of out-of-memory exceptions due to memory fragmentation. In the
  * example no specific limit is set, thus the
  * \ref helpers::VolumeGridHelper::DEFAULT_MAX_SEGMENT_BYTESIZE "default" is used.
  * Second, the `VolumeGridHelper` class creates a scene `Node` that represents the
  * partitioned `data` within the scene. This `Node` has one `Geometry` child per
  * volume partition.
  *
  * \subsection GeometryFeatures Geometry Features
  *
  * Each `%Geometry` node is rendered by the rendering stage with a matching geometry
  * type. Usually that rendering stage will query particular \em features from this
  * `%Geometry` object: Features are like components that make up the `%Geometry`
  * object in its entirety, but the `%Geometry` object *aggregates* them, i.e. does
  * not take their possession. This allows the same feature to be reused many times
  * across the scene, or even across many scenes. Rendering stages identify features
  * through the \em roles they take when associated with a `%Geometry` object.
  *
  * The geometry features API is documented \ref base::GeometryFeature "here".
  *
  * \subsubsection GeometryFeatureLifecycle The Lifecycle of Geometry Features
  *
  * Because of their shared-use nature, the lifecycle of geometry features is worth
  * taking a look at. They have neither a public constructor, nor a public
  * destructor:
  *
  *   - %Geometry features are acquired using their static `::%create` function.
  *     Conventionally, %Carna uses pointers in method interfaces when the object
  *     possession is transferred and C++ references when it is not. Each feature
  *     possess *itself*, hence that functions return references.
  *   - If you invoke `release` on the feature right after its creation, it will be
  *     deleted immediately because its unused.
  *   - By putting the feature on a `%Geometry` object, the feature notices that it
  *     got attached. You may `release` it now, but it will not be deleted until the
  *     `%Geometry` object it is attached to also dies.
  *
  * The idea is that the user invokes `release` on the feature as soon as it is sure
  * that the feature is not going to be attached to any *further* `%Geometry`
  * objects. The feature object is leaked when it never is released, in which case
  * you will also get an error message on the \ref base::Log "log" output.
  *
  * \subsubsection QuickStart_Materials Materials
  *
  * Materials determine how polygonal geometries are rendered. The core part of each
  * material is a \ref base::ShaderProgram "shader". Besides that, it can also have a
  * set of parameters that will be uploaded to the shader when the material is
  * applied, and it could enforce a particular
  * \ref base::RenderState "OpenGL render state".
  *
  * There are a few material shaders available out-of-the-box:
  *
  *   - The `solid` material shader colors the rendered mesh in a single color
  *     and performs phong lighting.
  *   - The `unshaded` material shader colors the rendered mesh in a single color
  *     uniformly. In the future this material shader will be replaced by `solid` in
  *     conjunction with *emission* color.
  *   - The \ref helpers::PointMarkerHelper class uses the `pointmarker` material
  *     shader to create simple markers in 3D space.
  *
  * The creation of custom materials is explained \ref CustomMaterials "here".
  */

}
